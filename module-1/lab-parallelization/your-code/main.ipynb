{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parallelization Lab\n",
    "\n",
    "In this lab, you will be leveraging several concepts you have learned to obtain a list of links from a web page and crawl and index the pages referenced by those links - both sequentially and in parallel. Follow the steps below to complete the lab."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Use the requests library to retrieve the content from the URL below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import requests as req\n",
    "#from bs4 import BeautifulSoup as bs\n",
    "\n",
    "url = 'https://en.wikipedia.org/wiki/Data_science'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Use BeautifulSoup to extract a list of all the unique links on the page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests as req\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#wiki_sopa = req.get(wiki_url).content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#wiki_tabla = wiki_sopa.find('div',{'class':'mw-parser-output'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://www.wikipedia.org/wiki/Information_science',\n",
       " 'https://www.wikipedia.org/wiki/Machine_learning',\n",
       " 'https://www.wikipedia.org/wiki/Data_mining',\n",
       " 'https://www.wikipedia.org/wiki/Statistical_classification',\n",
       " 'https://www.wikipedia.org/wiki/Cluster_analysis',\n",
       " 'https://www.wikipedia.org/wiki/Regression_analysis',\n",
       " 'https://www.wikipedia.org/wiki/Anomaly_detection',\n",
       " 'https://www.wikipedia.org/wiki/Automated_machine_learning',\n",
       " 'https://www.wikipedia.org/wiki/Association_rule_learning',\n",
       " 'https://www.wikipedia.org/wiki/Reinforcement_learning',\n",
       " 'https://www.wikipedia.org/wiki/Structured_prediction',\n",
       " 'https://www.wikipedia.org/wiki/Feature_engineering',\n",
       " 'https://www.wikipedia.org/wiki/Feature_learning',\n",
       " 'https://www.wikipedia.org/wiki/Online_machine_learning',\n",
       " 'https://www.wikipedia.org/wiki/Semi-supervised_learning',\n",
       " 'https://www.wikipedia.org/wiki/Unsupervised_learning',\n",
       " 'https://www.wikipedia.org/wiki/Learning_to_rank',\n",
       " 'https://www.wikipedia.org/wiki/Grammar_induction',\n",
       " 'https://www.wikipedia.org/wiki/Supervised_learning',\n",
       " 'https://www.wikipedia.org/wiki/Statistical_classification',\n",
       " 'https://www.wikipedia.org/wiki/Regression_analysis',\n",
       " 'https://www.wikipedia.org/wiki/Decision_tree_learning',\n",
       " 'https://www.wikipedia.org/wiki/Ensemble_learning',\n",
       " 'https://www.wikipedia.org/wiki/Bootstrap_aggregating',\n",
       " 'https://www.wikipedia.org/wiki/Boosting_(machine_learning)',\n",
       " 'https://www.wikipedia.org/wiki/Random_forest',\n",
       " 'https://www.wikipedia.org/wiki/K-nearest_neighbors_algorithm',\n",
       " 'https://www.wikipedia.org/wiki/Linear_regression',\n",
       " 'https://www.wikipedia.org/wiki/Naive_Bayes_classifier',\n",
       " 'https://www.wikipedia.org/wiki/Artificial_neural_network',\n",
       " 'https://www.wikipedia.org/wiki/Logistic_regression',\n",
       " 'https://www.wikipedia.org/wiki/Perceptron',\n",
       " 'https://www.wikipedia.org/wiki/Relevance_vector_machine',\n",
       " 'https://www.wikipedia.org/wiki/Support-vector_machine',\n",
       " 'https://www.wikipedia.org/wiki/Cluster_analysis',\n",
       " 'https://www.wikipedia.org/wiki/BIRCH',\n",
       " 'https://www.wikipedia.org/wiki/CURE_data_clustering_algorithm',\n",
       " 'https://www.wikipedia.org/wiki/Hierarchical_clustering',\n",
       " 'https://www.wikipedia.org/wiki/K-means_clustering',\n",
       " 'https://www.wikipedia.org/wiki/Expectation%E2%80%93maximization_algorithm',\n",
       " 'https://www.wikipedia.org/wiki/DBSCAN',\n",
       " 'https://www.wikipedia.org/wiki/OPTICS_algorithm',\n",
       " 'https://www.wikipedia.org/wiki/Mean-shift',\n",
       " 'https://www.wikipedia.org/wiki/Dimensionality_reduction',\n",
       " 'https://www.wikipedia.org/wiki/Factor_analysis',\n",
       " 'https://www.wikipedia.org/wiki/Canonical_correlation',\n",
       " 'https://www.wikipedia.org/wiki/Independent_component_analysis',\n",
       " 'https://www.wikipedia.org/wiki/Linear_discriminant_analysis',\n",
       " 'https://www.wikipedia.org/wiki/Non-negative_matrix_factorization',\n",
       " 'https://www.wikipedia.org/wiki/Principal_component_analysis',\n",
       " 'https://www.wikipedia.org/wiki/Proper_generalized_decomposition',\n",
       " 'https://www.wikipedia.org/wiki/T-distributed_stochastic_neighbor_embedding',\n",
       " 'https://www.wikipedia.org/wiki/Structured_prediction',\n",
       " 'https://www.wikipedia.org/wiki/Graphical_model',\n",
       " 'https://www.wikipedia.org/wiki/Bayesian_network',\n",
       " 'https://www.wikipedia.org/wiki/Conditional_random_field',\n",
       " 'https://www.wikipedia.org/wiki/Hidden_Markov_model',\n",
       " 'https://www.wikipedia.org/wiki/Anomaly_detection',\n",
       " 'https://www.wikipedia.org/wiki/K-nearest_neighbors_classification',\n",
       " 'https://www.wikipedia.org/wiki/Local_outlier_factor',\n",
       " 'https://www.wikipedia.org/wiki/Artificial_neural_network',\n",
       " 'https://www.wikipedia.org/wiki/Autoencoder',\n",
       " 'https://www.wikipedia.org/wiki/Deep_learning',\n",
       " 'https://www.wikipedia.org/wiki/DeepDream',\n",
       " 'https://www.wikipedia.org/wiki/Multilayer_perceptron',\n",
       " 'https://www.wikipedia.org/wiki/Recurrent_neural_network',\n",
       " 'https://www.wikipedia.org/wiki/Long_short-term_memory',\n",
       " 'https://www.wikipedia.org/wiki/Gated_recurrent_unit',\n",
       " 'https://www.wikipedia.org/wiki/Restricted_Boltzmann_machine',\n",
       " 'https://www.wikipedia.org/wiki/Generative_adversarial_network',\n",
       " 'https://www.wikipedia.org/wiki/Self-organizing_map',\n",
       " 'https://www.wikipedia.org/wiki/Convolutional_neural_network',\n",
       " 'https://www.wikipedia.org/wiki/U-Net',\n",
       " 'https://www.wikipedia.org/wiki/Reinforcement_learning',\n",
       " 'https://www.wikipedia.org/wiki/Q-learning',\n",
       " 'https://www.wikipedia.org/wiki/State%E2%80%93action%E2%80%93reward%E2%80%93state%E2%80%93action',\n",
       " 'https://www.wikipedia.org/wiki/Temporal_difference_learning',\n",
       " 'https://www.wikipedia.org/wiki/Bias%E2%80%93variance_dilemma',\n",
       " 'https://www.wikipedia.org/wiki/Computational_learning_theory',\n",
       " 'https://www.wikipedia.org/wiki/Empirical_risk_minimization',\n",
       " 'https://www.wikipedia.org/wiki/Occam_learning',\n",
       " 'https://www.wikipedia.org/wiki/Probably_approximately_correct_learning',\n",
       " 'https://www.wikipedia.org/wiki/Statistical_learning_theory',\n",
       " 'https://www.wikipedia.org/wiki/Vapnik%E2%80%93Chervonenkis_theory',\n",
       " 'https://www.wikipedia.org/wiki/Conference_on_Neural_Information_Processing_Systems',\n",
       " 'https://www.wikipedia.org/wiki/International_Conference_on_Machine_Learning',\n",
       " 'https://www.wikipedia.org/wiki/Machine_Learning_(journal)',\n",
       " 'https://www.wikipedia.org/wiki/Journal_of_Machine_Learning_Research',\n",
       " 'https://www.wikipedia.org/wiki/Glossary_of_artificial_intelligence',\n",
       " 'https://www.wikipedia.org/wiki/Glossary_of_artificial_intelligence',\n",
       " 'https://www.wikipedia.org/wiki/List_of_datasets_for_machine-learning_research',\n",
       " 'https://www.wikipedia.org/wiki/Outline_of_machine_learning',\n",
       " 'https://www.wikipedia.org/wiki/Template:Machine_learning_bar',\n",
       " 'https://www.wikipedia.org/wiki/Template_talk:Machine_learning_bar',\n",
       " 'https://www.wikipedia.org/wiki/Inter-disciplinary',\n",
       " 'https://www.wikipedia.org/wiki/Knowledge',\n",
       " 'https://www.wikipedia.org/wiki/Unstructured_data',\n",
       " 'https://www.wikipedia.org/wiki/Data_mining',\n",
       " 'https://www.wikipedia.org/wiki/Machine_learning',\n",
       " 'https://www.wikipedia.org/wiki/Big_data',\n",
       " 'https://www.wikipedia.org/wiki/Statistics',\n",
       " 'https://www.wikipedia.org/wiki/Data_analysis',\n",
       " 'https://www.wikipedia.org/wiki/Machine_learning',\n",
       " 'https://www.wikipedia.org/wiki/Domain_knowledge',\n",
       " 'https://www.wikipedia.org/wiki/Mathematics',\n",
       " 'https://www.wikipedia.org/wiki/Statistics',\n",
       " 'https://www.wikipedia.org/wiki/Computer_science',\n",
       " 'https://www.wikipedia.org/wiki/Domain_knowledge',\n",
       " 'https://www.wikipedia.org/wiki/Information_science',\n",
       " 'https://www.wikipedia.org/wiki/Turing_award',\n",
       " 'https://www.wikipedia.org/wiki/Jim_Gray_(computer_scientist)',\n",
       " 'https://www.wikipedia.org/wiki/Empirical_research',\n",
       " 'https://www.wikipedia.org/wiki/Basic_research',\n",
       " 'https://www.wikipedia.org/wiki/Computational_science',\n",
       " 'https://www.wikipedia.org/wiki/Information_explosion',\n",
       " 'https://www.wikipedia.org/wiki/Big_data',\n",
       " 'https://www.wikipedia.org/wiki/Information_visualization',\n",
       " 'https://www.wikipedia.org/wiki/Complex_systems',\n",
       " 'https://www.wikipedia.org/wiki/Communication',\n",
       " 'https://www.wikipedia.org/wiki/Buzzword_bingo',\n",
       " 'https://www.wikipedia.org/wiki/Nathan_Yau',\n",
       " 'https://www.wikipedia.org/wiki/Ben_Fry',\n",
       " 'https://www.wikipedia.org/wiki/Human%E2%80%93computer_interaction',\n",
       " 'https://www.wikipedia.org/wiki/American_Statistical_Association',\n",
       " 'https://www.wikipedia.org/wiki/Database',\n",
       " 'https://www.wikipedia.org/wiki/Machine_learning',\n",
       " 'https://www.wikipedia.org/wiki/Distributed_computing',\n",
       " 'https://www.wikipedia.org/wiki/Nate_Silver',\n",
       " 'https://www.wikipedia.org/wiki/Vasant_Dhar',\n",
       " 'https://www.wikipedia.org/wiki/Andrew_Gelman',\n",
       " 'https://www.wikipedia.org/wiki/David_Donoho',\n",
       " 'https://www.wikipedia.org/wiki/John_Tukey',\n",
       " 'https://www.wikipedia.org/wiki/Montpellier_2_University',\n",
       " 'https://www.wikipedia.org/wiki/Peter_Naur',\n",
       " 'https://www.wikipedia.org/wiki/C.F._Jeff_Wu',\n",
       " 'https://www.wikipedia.org/wiki/William_S._Cleveland',\n",
       " 'https://www.wikipedia.org/wiki/Committee_on_Data_for_Science_and_Technology',\n",
       " 'https://www.wikipedia.org/wiki/American_Statistical_Association',\n",
       " 'https://www.wikipedia.org/wiki/DJ_Patil',\n",
       " 'https://www.wikipedia.org/wiki/Jeff_Hammerbacher',\n",
       " 'https://www.wikipedia.org/wiki/National_Science_Board',\n",
       " 'https://www.wikipedia.org/wiki/Wikipedia:LSC',\n",
       " 'https://www.wikipedia.org/wiki/Wikipedia:Manual_of_Style/Stand-alone_lists',\n",
       " 'https://www.wikipedia.org/wiki/Talk:Data_science',\n",
       " 'https://www.wikipedia.org/wiki/Linear_regression',\n",
       " 'https://www.wikipedia.org/wiki/Logistic_regression',\n",
       " 'https://www.wikipedia.org/wiki/Support_vector_machine',\n",
       " 'https://www.wikipedia.org/wiki/Cluster_analysis',\n",
       " 'https://www.wikipedia.org/wiki/Dimensionality_reduction',\n",
       " 'https://www.wikipedia.org/wiki/Machine_learning',\n",
       " 'https://www.wikipedia.org/wiki/Python_(programming_language)',\n",
       " 'https://www.wikipedia.org/wiki/R_(programming_language)',\n",
       " 'https://www.wikipedia.org/wiki/Julia_(programming_language)',\n",
       " 'https://www.wikipedia.org/wiki/TensorFlow',\n",
       " 'https://www.wikipedia.org/wiki/Pytorch',\n",
       " 'https://www.wikipedia.org/wiki/Jupyter_Notebook',\n",
       " 'https://www.wikipedia.org/wiki/Apache_Hadoop',\n",
       " 'https://www.wikipedia.org/wiki/Plotly',\n",
       " 'https://www.wikipedia.org/wiki/Tableau_Software',\n",
       " 'https://www.wikipedia.org/wiki/Microsoft_Power_BI',\n",
       " 'https://www.wikipedia.org/wiki/Qlik',\n",
       " 'https://www.wikipedia.org/wiki/AnyChart',\n",
       " 'https://www.wikipedia.org/wiki/Google_Charts',\n",
       " 'https://www.wikipedia.org/wiki/Sisense',\n",
       " 'https://www.wikipedia.org/wiki/Webix',\n",
       " 'https://www.wikipedia.org/wiki/RapidMiner',\n",
       " 'https://www.wikipedia.org/wiki/Dataiku',\n",
       " 'https://www.wikipedia.org/wiki/Anaconda_(Python_distribution)',\n",
       " 'https://www.wikipedia.org/wiki/MATLAB',\n",
       " 'https://www.wikipedia.org/wiki/Doi_(identifier)',\n",
       " 'https://www.wikipedia.org/wiki/Jeffrey_T._Leek',\n",
       " 'https://www.wikipedia.org/wiki/Doi_(identifier)',\n",
       " 'https://www.wikipedia.org/wiki/ISBN_(identifier)',\n",
       " 'https://www.wikipedia.org/wiki/Special:BookSources/9784431702085',\n",
       " 'https://www.wikipedia.org/wiki/ISBN_(identifier)',\n",
       " 'https://www.wikipedia.org/wiki/Special:BookSources/978-0-9825442-0-4',\n",
       " 'https://www.wikipedia.org/wiki/Doi_(identifier)',\n",
       " 'https://www.wikipedia.org/wiki/ISSN_(identifier)',\n",
       " 'https://www.wikipedia.org/wiki/PMID_(identifier)',\n",
       " 'https://www.wikipedia.org/wiki/American_Statistical_Association',\n",
       " 'https://www.wikipedia.org/wiki/Doi_(identifier)',\n",
       " 'https://www.wikipedia.org/wiki/ISBN_(identifier)',\n",
       " 'https://www.wikipedia.org/wiki/Special:BookSources/0-12-241770-4',\n",
       " 'https://www.wikipedia.org/wiki/OCLC_(identifier)',\n",
       " 'https://www.wikipedia.org/wiki/Category:CS1_maint:_others',\n",
       " 'https://www.wikipedia.org/wiki/Doi_(identifier)',\n",
       " 'https://www.wikipedia.org/wiki/Doi_(identifier)',\n",
       " 'https://www.wikipedia.org/wiki/ISSN_(identifier)',\n",
       " 'https://www.wikipedia.org/wiki/Template:Data',\n",
       " 'https://www.wikipedia.org/wiki/Template_talk:Data',\n",
       " 'https://www.wikipedia.org/wiki/Data_(computing)',\n",
       " 'https://www.wikipedia.org/wiki/Data_analysis',\n",
       " 'https://www.wikipedia.org/wiki/Data_archaeology',\n",
       " 'https://www.wikipedia.org/wiki/Data_cleansing',\n",
       " 'https://www.wikipedia.org/wiki/Data_collection',\n",
       " 'https://www.wikipedia.org/wiki/Data_compression',\n",
       " 'https://www.wikipedia.org/wiki/Data_corruption',\n",
       " 'https://www.wikipedia.org/wiki/Data_curation',\n",
       " 'https://www.wikipedia.org/wiki/Data_degradation',\n",
       " 'https://www.wikipedia.org/wiki/Data_editing',\n",
       " 'https://www.wikipedia.org/wiki/Extract,_transform,_load',\n",
       " 'https://www.wikipedia.org/wiki/Data_farming',\n",
       " 'https://www.wikipedia.org/wiki/Data_format_management',\n",
       " 'https://www.wikipedia.org/wiki/Data_fusion',\n",
       " 'https://www.wikipedia.org/wiki/Data_integration',\n",
       " 'https://www.wikipedia.org/wiki/Data_integrity',\n",
       " 'https://www.wikipedia.org/wiki/Data_library',\n",
       " 'https://www.wikipedia.org/wiki/Data_loss',\n",
       " 'https://www.wikipedia.org/wiki/Data_management',\n",
       " 'https://www.wikipedia.org/wiki/Data_migration',\n",
       " 'https://www.wikipedia.org/wiki/Data_mining',\n",
       " 'https://www.wikipedia.org/wiki/Data_pre-processing',\n",
       " 'https://www.wikipedia.org/wiki/Data_preservation',\n",
       " 'https://www.wikipedia.org/wiki/Information_privacy',\n",
       " 'https://www.wikipedia.org/wiki/Data_recovery',\n",
       " 'https://www.wikipedia.org/wiki/Data_reduction',\n",
       " 'https://www.wikipedia.org/wiki/Data_retention',\n",
       " 'https://www.wikipedia.org/wiki/Data_quality',\n",
       " 'https://www.wikipedia.org/wiki/Data_scraping',\n",
       " 'https://www.wikipedia.org/wiki/Data_scrubbing',\n",
       " 'https://www.wikipedia.org/wiki/Data_security',\n",
       " 'https://www.wikipedia.org/wiki/Data_steward',\n",
       " 'https://www.wikipedia.org/wiki/Data_storage',\n",
       " 'https://www.wikipedia.org/wiki/Data_validation',\n",
       " 'https://www.wikipedia.org/wiki/Data_warehouse',\n",
       " 'https://www.wikipedia.org/wiki/Data_wrangling']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki_url = req.get('https://en.wikipedia.org/wiki/Data_science').content\n",
    "wiki_sopa = bs(wiki_url, 'html.parser')\n",
    "wiki_tabla = wiki_sopa.find('div',{'class':'mw-parser-output'})\n",
    "wiki_body = wiki_tabla.findAll('a')\n",
    "wiki_links = re.findall('\\/\\wiki.+?\\\"', str(wiki_body))\n",
    "for i in range(len(wiki_links)):    # this is to remove the \" at the end of string\n",
    "    wiki_links[i] = wiki_links[i][0:-1]\n",
    "wiki_lst = ['https://www.wikipedia.org' + sub for sub in wiki_links] \n",
    "wiki_lst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Use list comprehensions with conditions to clean the link list.\n",
    "\n",
    "There are two types of links, absolute and relative. Absolute links have the full URL and begin with http while relative links begin with a forward slash (/) and point to an internal page within the wikipedia.org domain. Clean the respective types of URLs as follows.\n",
    "\n",
    "- Absolute Links: Create a list of these and remove any that contain a percentage sign (%).\n",
    "- Relativel Links: Create a list of these, add the domain to the link so that you have the full URL, and remove any that contain a percentage sign (%).\n",
    "- Combine the list of absolute and relative links and ensure there are no duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain = 'http://wikipedia.org'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://www.wikipedia.org/wiki/Empirical_risk_minimization',\n",
       " 'https://www.wikipedia.org/wiki/Data_library',\n",
       " 'https://www.wikipedia.org/wiki/Online_machine_learning',\n",
       " 'https://www.wikipedia.org/wiki/Recurrent_neural_network',\n",
       " 'https://www.wikipedia.org/wiki/Reinforcement_learning',\n",
       " 'https://www.wikipedia.org/wiki/Pytorch',\n",
       " 'https://www.wikipedia.org/wiki/Communication',\n",
       " 'https://www.wikipedia.org/wiki/Data_integrity',\n",
       " 'https://www.wikipedia.org/wiki/Bayesian_network',\n",
       " 'https://www.wikipedia.org/wiki/Information_explosion',\n",
       " 'https://www.wikipedia.org/wiki/Multilayer_perceptron',\n",
       " 'https://www.wikipedia.org/wiki/Wikipedia:LSC',\n",
       " 'https://www.wikipedia.org/wiki/Feature_learning',\n",
       " 'https://www.wikipedia.org/wiki/Statistics',\n",
       " 'https://www.wikipedia.org/wiki/Extract,_transform,_load',\n",
       " 'https://www.wikipedia.org/wiki/Decision_tree_learning',\n",
       " 'https://www.wikipedia.org/wiki/Support-vector_machine',\n",
       " 'https://www.wikipedia.org/wiki/Canonical_correlation',\n",
       " 'https://www.wikipedia.org/wiki/Data_loss',\n",
       " 'https://www.wikipedia.org/wiki/Jeffrey_T._Leek',\n",
       " 'https://www.wikipedia.org/wiki/Category:CS1_maint:_others',\n",
       " 'https://www.wikipedia.org/wiki/Data_management',\n",
       " 'https://www.wikipedia.org/wiki/Complex_systems',\n",
       " 'https://www.wikipedia.org/wiki/Semi-supervised_learning',\n",
       " 'https://www.wikipedia.org/wiki/DeepDream',\n",
       " 'https://www.wikipedia.org/wiki/Data_validation',\n",
       " 'https://www.wikipedia.org/wiki/John_Tukey',\n",
       " 'https://www.wikipedia.org/wiki/Machine_learning',\n",
       " 'https://www.wikipedia.org/wiki/Data_pre-processing',\n",
       " 'https://www.wikipedia.org/wiki/PMID_(identifier)',\n",
       " 'https://www.wikipedia.org/wiki/Montpellier_2_University',\n",
       " 'https://www.wikipedia.org/wiki/Andrew_Gelman',\n",
       " 'https://www.wikipedia.org/wiki/Data_quality',\n",
       " 'https://www.wikipedia.org/wiki/Hidden_Markov_model',\n",
       " 'https://www.wikipedia.org/wiki/Database',\n",
       " 'https://www.wikipedia.org/wiki/Machine_Learning_(journal)',\n",
       " 'https://www.wikipedia.org/wiki/Learning_to_rank',\n",
       " 'https://www.wikipedia.org/wiki/Local_outlier_factor',\n",
       " 'https://www.wikipedia.org/wiki/Conditional_random_field',\n",
       " 'https://www.wikipedia.org/wiki/Special:BookSources/9784431702085',\n",
       " 'https://www.wikipedia.org/wiki/Ensemble_learning',\n",
       " 'https://www.wikipedia.org/wiki/Restricted_Boltzmann_machine',\n",
       " 'https://www.wikipedia.org/wiki/Statistical_classification',\n",
       " 'https://www.wikipedia.org/wiki/C.F._Jeff_Wu',\n",
       " 'https://www.wikipedia.org/wiki/Dataiku',\n",
       " 'https://www.wikipedia.org/wiki/Association_rule_learning',\n",
       " 'https://www.wikipedia.org/wiki/David_Donoho',\n",
       " 'https://www.wikipedia.org/wiki/Nathan_Yau',\n",
       " 'https://www.wikipedia.org/wiki/BIRCH',\n",
       " 'https://www.wikipedia.org/wiki/Grammar_induction',\n",
       " 'https://www.wikipedia.org/wiki/Template:Data',\n",
       " 'https://www.wikipedia.org/wiki/Basic_research',\n",
       " 'https://www.wikipedia.org/wiki/Data_scraping',\n",
       " 'https://www.wikipedia.org/wiki/Deep_learning',\n",
       " 'https://www.wikipedia.org/wiki/Temporal_difference_learning',\n",
       " 'https://www.wikipedia.org/wiki/Data_wrangling',\n",
       " 'https://www.wikipedia.org/wiki/Automated_machine_learning',\n",
       " 'https://www.wikipedia.org/wiki/Apache_Hadoop',\n",
       " 'https://www.wikipedia.org/wiki/International_Conference_on_Machine_Learning',\n",
       " 'https://www.wikipedia.org/wiki/Bootstrap_aggregating',\n",
       " 'https://www.wikipedia.org/wiki/Data_fusion',\n",
       " 'https://www.wikipedia.org/wiki/Julia_(programming_language)',\n",
       " 'https://www.wikipedia.org/wiki/List_of_datasets_for_machine-learning_research',\n",
       " 'https://www.wikipedia.org/wiki/Doi_(identifier)',\n",
       " 'https://www.wikipedia.org/wiki/Vasant_Dhar',\n",
       " 'https://www.wikipedia.org/wiki/Computational_learning_theory',\n",
       " 'https://www.wikipedia.org/wiki/William_S._Cleveland',\n",
       " 'https://www.wikipedia.org/wiki/Independent_component_analysis',\n",
       " 'https://www.wikipedia.org/wiki/Data_collection',\n",
       " 'https://www.wikipedia.org/wiki/Buzzword_bingo',\n",
       " 'https://www.wikipedia.org/wiki/Outline_of_machine_learning',\n",
       " 'https://www.wikipedia.org/wiki/ISSN_(identifier)',\n",
       " 'https://www.wikipedia.org/wiki/Proper_generalized_decomposition',\n",
       " 'https://www.wikipedia.org/wiki/Generative_adversarial_network',\n",
       " 'https://www.wikipedia.org/wiki/Data_warehouse',\n",
       " 'https://www.wikipedia.org/wiki/R_(programming_language)',\n",
       " 'https://www.wikipedia.org/wiki/Convolutional_neural_network',\n",
       " 'https://www.wikipedia.org/wiki/Data_reduction',\n",
       " 'https://www.wikipedia.org/wiki/Template_talk:Machine_learning_bar',\n",
       " 'https://www.wikipedia.org/wiki/Non-negative_matrix_factorization',\n",
       " 'https://www.wikipedia.org/wiki/Jeff_Hammerbacher',\n",
       " 'https://www.wikipedia.org/wiki/Qlik',\n",
       " 'https://www.wikipedia.org/wiki/Data_degradation',\n",
       " 'https://www.wikipedia.org/wiki/Unsupervised_learning',\n",
       " 'https://www.wikipedia.org/wiki/Supervised_learning',\n",
       " 'https://www.wikipedia.org/wiki/Logistic_regression',\n",
       " 'https://www.wikipedia.org/wiki/Regression_analysis',\n",
       " 'https://www.wikipedia.org/wiki/Knowledge',\n",
       " 'https://www.wikipedia.org/wiki/Artificial_neural_network',\n",
       " 'https://www.wikipedia.org/wiki/OPTICS_algorithm',\n",
       " 'https://www.wikipedia.org/wiki/Data_integration',\n",
       " 'https://www.wikipedia.org/wiki/Naive_Bayes_classifier',\n",
       " 'https://www.wikipedia.org/wiki/Nate_Silver',\n",
       " 'https://www.wikipedia.org/wiki/Graphical_model',\n",
       " 'https://www.wikipedia.org/wiki/National_Science_Board',\n",
       " 'https://www.wikipedia.org/wiki/Perceptron',\n",
       " 'https://www.wikipedia.org/wiki/Empirical_research',\n",
       " 'https://www.wikipedia.org/wiki/Data_editing',\n",
       " 'https://www.wikipedia.org/wiki/Microsoft_Power_BI',\n",
       " 'https://www.wikipedia.org/wiki/Information_science',\n",
       " 'https://www.wikipedia.org/wiki/Data_retention',\n",
       " 'https://www.wikipedia.org/wiki/Data_(computing)',\n",
       " 'https://www.wikipedia.org/wiki/Q-learning',\n",
       " 'https://www.wikipedia.org/wiki/RapidMiner',\n",
       " 'https://www.wikipedia.org/wiki/Journal_of_Machine_Learning_Research',\n",
       " 'https://www.wikipedia.org/wiki/Peter_Naur',\n",
       " 'https://www.wikipedia.org/wiki/Mathematics',\n",
       " 'https://www.wikipedia.org/wiki/Data_analysis',\n",
       " 'https://www.wikipedia.org/wiki/Big_data',\n",
       " 'https://www.wikipedia.org/wiki/Wikipedia:Manual_of_Style/Stand-alone_lists',\n",
       " 'https://www.wikipedia.org/wiki/Relevance_vector_machine',\n",
       " 'https://www.wikipedia.org/wiki/Special:BookSources/0-12-241770-4',\n",
       " 'https://www.wikipedia.org/wiki/Long_short-term_memory',\n",
       " 'https://www.wikipedia.org/wiki/Data_compression',\n",
       " 'https://www.wikipedia.org/wiki/Conference_on_Neural_Information_Processing_Systems',\n",
       " 'https://www.wikipedia.org/wiki/Python_(programming_language)',\n",
       " 'https://www.wikipedia.org/wiki/DJ_Patil',\n",
       " 'https://www.wikipedia.org/wiki/Data_recovery',\n",
       " 'https://www.wikipedia.org/wiki/Sisense',\n",
       " 'https://www.wikipedia.org/wiki/K-nearest_neighbors_algorithm',\n",
       " 'https://www.wikipedia.org/wiki/Linear_discriminant_analysis',\n",
       " 'https://www.wikipedia.org/wiki/Data_scrubbing',\n",
       " 'https://www.wikipedia.org/wiki/Data_farming',\n",
       " 'https://www.wikipedia.org/wiki/Special:BookSources/978-0-9825442-0-4',\n",
       " 'https://www.wikipedia.org/wiki/Computer_science',\n",
       " 'https://www.wikipedia.org/wiki/Hierarchical_clustering',\n",
       " 'https://www.wikipedia.org/wiki/Domain_knowledge',\n",
       " 'https://www.wikipedia.org/wiki/Data_curation',\n",
       " 'https://www.wikipedia.org/wiki/CURE_data_clustering_algorithm',\n",
       " 'https://www.wikipedia.org/wiki/Linear_regression',\n",
       " 'https://www.wikipedia.org/wiki/DBSCAN',\n",
       " 'https://www.wikipedia.org/wiki/Data_archaeology',\n",
       " 'https://www.wikipedia.org/wiki/Data_migration',\n",
       " 'https://www.wikipedia.org/wiki/Anomaly_detection',\n",
       " 'https://www.wikipedia.org/wiki/Gated_recurrent_unit',\n",
       " 'https://www.wikipedia.org/wiki/Factor_analysis',\n",
       " 'https://www.wikipedia.org/wiki/Random_forest',\n",
       " 'https://www.wikipedia.org/wiki/Support_vector_machine',\n",
       " 'https://www.wikipedia.org/wiki/Data_storage',\n",
       " 'https://www.wikipedia.org/wiki/Webix',\n",
       " 'https://www.wikipedia.org/wiki/ISBN_(identifier)',\n",
       " 'https://www.wikipedia.org/wiki/OCLC_(identifier)',\n",
       " 'https://www.wikipedia.org/wiki/Turing_award',\n",
       " 'https://www.wikipedia.org/wiki/AnyChart',\n",
       " 'https://www.wikipedia.org/wiki/Data_steward',\n",
       " 'https://www.wikipedia.org/wiki/Autoencoder',\n",
       " 'https://www.wikipedia.org/wiki/Unstructured_data',\n",
       " 'https://www.wikipedia.org/wiki/Cluster_analysis',\n",
       " 'https://www.wikipedia.org/wiki/Feature_engineering',\n",
       " 'https://www.wikipedia.org/wiki/TensorFlow',\n",
       " 'https://www.wikipedia.org/wiki/U-Net',\n",
       " 'https://www.wikipedia.org/wiki/Principal_component_analysis',\n",
       " 'https://www.wikipedia.org/wiki/Tableau_Software',\n",
       " 'https://www.wikipedia.org/wiki/Information_privacy',\n",
       " 'https://www.wikipedia.org/wiki/Inter-disciplinary',\n",
       " 'https://www.wikipedia.org/wiki/Template_talk:Data',\n",
       " 'https://www.wikipedia.org/wiki/Data_format_management',\n",
       " 'https://www.wikipedia.org/wiki/Data_security',\n",
       " 'https://www.wikipedia.org/wiki/Distributed_computing',\n",
       " 'https://www.wikipedia.org/wiki/Jupyter_Notebook',\n",
       " 'https://www.wikipedia.org/wiki/Dimensionality_reduction',\n",
       " 'https://www.wikipedia.org/wiki/Plotly',\n",
       " 'https://www.wikipedia.org/wiki/Data_mining',\n",
       " 'https://www.wikipedia.org/wiki/Template:Machine_learning_bar',\n",
       " 'https://www.wikipedia.org/wiki/K-means_clustering',\n",
       " 'https://www.wikipedia.org/wiki/K-nearest_neighbors_classification',\n",
       " 'https://www.wikipedia.org/wiki/Structured_prediction',\n",
       " 'https://www.wikipedia.org/wiki/Google_Charts',\n",
       " 'https://www.wikipedia.org/wiki/Mean-shift',\n",
       " 'https://www.wikipedia.org/wiki/Data_corruption',\n",
       " 'https://www.wikipedia.org/wiki/Occam_learning',\n",
       " 'https://www.wikipedia.org/wiki/Talk:Data_science',\n",
       " 'https://www.wikipedia.org/wiki/Ben_Fry',\n",
       " 'https://www.wikipedia.org/wiki/Boosting_(machine_learning)',\n",
       " 'https://www.wikipedia.org/wiki/Self-organizing_map',\n",
       " 'https://www.wikipedia.org/wiki/Glossary_of_artificial_intelligence',\n",
       " 'https://www.wikipedia.org/wiki/Computational_science',\n",
       " 'https://www.wikipedia.org/wiki/MATLAB',\n",
       " 'https://www.wikipedia.org/wiki/American_Statistical_Association',\n",
       " 'https://www.wikipedia.org/wiki/Probably_approximately_correct_learning',\n",
       " 'https://www.wikipedia.org/wiki/Jim_Gray_(computer_scientist)',\n",
       " 'https://www.wikipedia.org/wiki/Data_cleansing',\n",
       " 'https://www.wikipedia.org/wiki/Information_visualization',\n",
       " 'https://www.wikipedia.org/wiki/Data_preservation',\n",
       " 'https://www.wikipedia.org/wiki/Committee_on_Data_for_Science_and_Technology',\n",
       " 'https://www.wikipedia.org/wiki/Anaconda_(Python_distribution)',\n",
       " 'https://www.wikipedia.org/wiki/T-distributed_stochastic_neighbor_embedding',\n",
       " 'https://www.wikipedia.org/wiki/Statistical_learning_theory']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_wiki_set_lst = list(set(i for i in wiki_lst if '%' not in i))\n",
    "clean_wiki_set_lst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Use the os library to create a folder called *wikipedia* and make that the current working directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# got example from \n",
    "# https://stackabuse.com/creating-and-deleting-directories-with-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The current working directory is C:\\Users\\dxoco\\Desktop\\IronHack\\datamex_082020\\module-1\\lab-parallelization\\your-code\n"
     ]
    }
   ],
   "source": [
    "path = os.getcwd()\n",
    "print (\"The current working directory is %s\" % path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#path = 'c:/users/dxoco/desktop/ironhack/datamex_082020/module-1/lab-parallelization/your-code/newdir' #try1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#os.mkdir('newdir2')  # try2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#os.mkdir('wikipedia')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Write a function called index_page that accepts a link and does the following.\n",
    "\n",
    "- Tries to request the content of the page referenced by that link.\n",
    "- Slugifies the filename using the `slugify` function from the [python-slugify](https://pypi.org/project/python-slugify/) library and adds a .html file extension.\n",
    "    - If you don't already have the python-slugify library installed, you can pip install it as follows: `$ pip install python-slugify`.\n",
    "    - To import the slugify function, you would do the following: `from slugify import slugify`.\n",
    "    - You can then slugify a link as follows `slugify(link)`.\n",
    "- Creates a file in the wikipedia folder using the slugified filename and writes the contents of the page to the file.\n",
    "- If an exception occurs during the process above, just `pass`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from slugify import slugify\n",
    "import csv\n",
    "import unidecode\n",
    "import requests as req\n",
    "from bs4 import BeautifulSoup as bs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# m1lp -> module-1 lab-par\n",
    "def index_page(link):\n",
    "    # god save the queen and let me specify the working directory to avoid a huge mess on my folders:\n",
    "    os.chdir('c:/users/dxoco/desktop/ironhack/datamex_082020/module-1/lab-parallelization/your-code/wikipedia')\n",
    "    try:\n",
    "        m1lp_data = req.get(link).content\n",
    "        m1lp_sopa_str = str(bs(m1lp_data, 'html.parser')) # it's shorter to change dtype at this point\n",
    "        filename_con_html = slugify(link)+'.html' # it's shorter to concatenate \" .html \" here\n",
    "        with open(filename_con_html, 'w', encoding=\"utf-8\") as filehandle: # remember to always specify enconding\n",
    "            filehandle.write(m1lp_sopa_str)\n",
    "    except:\n",
    "        pass\n",
    "# so, if not specified as ** encoding=\"utf-8\" ** it will fail\n",
    "# how de codec issue was solved:\n",
    "# https://stackoverflow.com/questions/27092833/unicodeencodeerror-charmap-codec-cant-encode-characters\n",
    "# and source for the text writing:\n",
    "# https://stackabuse.com/reading-and-writing-lists-to-a-file-in-python/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Sequentially loop through the list of links, running the index_page function each time.\n",
    "\n",
    "Remember to include `%%time` at the beginning of the cell so that it measures the time it takes for the cell to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2min 12s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for i in range(len(clean_wiki_set_lst)):\n",
    "    index_page(clean_wiki_set_lst[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Perform the page indexing in parallel and note the difference in performance.\n",
    "\n",
    "Remember to include `%%time` at the beginning of the cell so that it measures the time it takes for the cell to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 5.99 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from index_page import index_page\n",
    "from multiprocessing import Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None]\n",
      "Wall time: 18.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if __name__ == '__main__':\n",
    "    with Pool(8) as p:\n",
    "        print(p.map(index_page, clean_wiki_set_lst))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
